{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "openai.api_key = \"\"\n",
    "# openai.Model.list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.7, # default is 1 this is the degree of randomness of the model's output\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "import ast\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "data = json.load(open(\"factchecks.json\", 'r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(data)):\n",
    "    print(i)\n",
    "    text = data[i]['claim']\n",
    "    prompt = f\"\"\"\n",
    "    Generate ten different tweets about the text delimited by triple backticks.\n",
    "    Make sure that generated tweets should not be a fact-check or a debunk.\n",
    "    Also, tweets should have different hashtags.\n",
    "    ```{text}```\n",
    "    \"\"\"\n",
    "    max_attempts = 5\n",
    "    for j in range(max_attempts):\n",
    "        try:\n",
    "            response = get_completion(prompt)\n",
    "            break\n",
    "        except Exception as e:\n",
    "            time.sleep(2)\n",
    "            print(f\"Error occurred: {e}\")\n",
    "            print(f\"Retrying ({j+1}/{max_attempts})...\")\n",
    "    if j == max_attempts - 1:\n",
    "        print(\"Maximum retries exceeded. Stopping at \", i)\n",
    "        break\n",
    "        \n",
    "    data[i]['chatgpt_gen'] = response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "for i in range(len(data)):\n",
    "    text = \"\\n\"+data[i]['chatgpt_gen']\n",
    "    if \"1)\" in data[i]['chatgpt_gen'] and \"2)\" in data[i]['chatgpt_gen'] and \"3)\" in data[i]['chatgpt_gen']:\n",
    "        items = re.split(r'\\n\\d+\\)\\s+', text)[1:]\n",
    "    elif \"Tweet 1:\" in data[i]['chatgpt_gen'] and \"Tweet 2:\" in data[i]['chatgpt_gen'] and \"Tweet 3:\" in data[i]['chatgpt_gen']:\n",
    "        items = re.split(r'\\nTweet \\d+\\:\\s+', text)[1:]\n",
    "    else:\n",
    "        items = re.split(r'\\n\\d+\\.\\s+', text)[1:]\n",
    "    items = [item.strip() for item in items]\n",
    "    items = [item.strip('\"') for item in items]\n",
    "    if len(items) != 5: print(i)\n",
    "    data[i]['chatgpt_gen_list'] = items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CahtGPTMisinfo.json', 'w') as fp:\n",
    "    json.dump(data, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing selfBLEU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_metric\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "import numpy as np\n",
    "import copy\n",
    "metric = load_metric(\"bleu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score1 = []\n",
    "final_score2 = []\n",
    "final_score3 = []\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    p = data[i]['chatgpt_gen'][:5]\n",
    "    def calculate_selfBleu(sentences, order):\n",
    "        def get_bleu_score(sentence, remaining_sentences, order):\n",
    "            lst = []\n",
    "            for i in remaining_sentences:\n",
    "                preds = [sentence.lower().split()]\n",
    "                labels = [[i.lower().split()]]\n",
    "                bleu = metric.compute(predictions=preds, references=labels, max_order=int(order))\n",
    "                lst.append(bleu['bleu'])\n",
    "            return lst\n",
    "        bleu_scores = []\n",
    "        for i in sentences:\n",
    "            sentences_copy = copy.deepcopy(sentences)\n",
    "            remaining_sentences = sentences_copy.remove(i)\n",
    "            bleu = get_bleu_score(i, sentences_copy, order)\n",
    "            bleu_scores.append(bleu)\n",
    "        return np.mean(bleu_scores)\n",
    "    \n",
    "    final_score1.append(calculate_selfBleu(p, 1))\n",
    "    final_score2.append(calculate_selfBleu(p, 2))\n",
    "    final_score3.append(calculate_selfBleu(p, 3))\n",
    "    \n",
    "print(sum(final_score1)/len(final_score1))\n",
    "print(sum(final_score2)/len(final_score2))\n",
    "print(sum(final_score3)/len(final_score3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score1 = []\n",
    "final_score2 = []\n",
    "final_score3 = []\n",
    "from tqdm import tqdm\n",
    "\n",
    "for i in tqdm(range(len(data))):\n",
    "    p = data[i]['generatedT5Misinfo'][:5]\n",
    "    def calculate_selfBleu(sentences, order):\n",
    "        def get_bleu_score(sentence, remaining_sentences, order):\n",
    "            lst = []\n",
    "            for i in remaining_sentences:\n",
    "                preds = [sentence.lower().split()]\n",
    "                labels = [[i.lower().split()]]\n",
    "                bleu = metric.compute(predictions=preds, references=labels, max_order=int(order))\n",
    "                lst.append(bleu['bleu'])\n",
    "            return lst\n",
    "        bleu_scores = []\n",
    "        for i in sentences:\n",
    "            sentences_copy = copy.deepcopy(sentences)\n",
    "            remaining_sentences = sentences_copy.remove(i)\n",
    "            bleu = get_bleu_score(i, sentences_copy, order)\n",
    "            bleu_scores.append(bleu)\n",
    "        return np.mean(bleu_scores)\n",
    "    \n",
    "    final_score1.append(calculate_selfBleu(p, 1))\n",
    "    final_score2.append(calculate_selfBleu(p, 2))\n",
    "    final_score3.append(calculate_selfBleu(p, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:gpu2] *",
   "language": "python",
   "name": "conda-env-gpu2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
